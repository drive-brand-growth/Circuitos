# Agent Orchestration Quick Reference
**Token-Optimized Multi-Agent Collaboration Framework**

---

## üöÄ Quick Start Commands

### Activate Project Orchestrator
```
"Use project orchestrator to [build/analyze/implement] [project description]"
```

### Manual Agent Control
```
"Launch [Explore/Plan/General-Purpose] agent with [Haiku/Sonnet] to [task]"
```

### Token Optimization
```
"Token-optimized approach to [task]"
"Use Haiku for [simple tasks], Sonnet for [complex tasks]"
```

---

## üéØ Agent Selection Matrix

| Task Type | Agent | Model | Token Cost | Example |
|-----------|-------|-------|------------|---------|
| **Find code patterns** | Explore | Haiku | 500-2K | "Where is authentication handled?" |
| **Map codebase structure** | Explore | Haiku | 1-3K | "What's the project architecture?" |
| **Quick file search** | Direct Grep/Glob | N/A | 100-500 | "Find all *.tsx files" |
| **Plan implementation** | Plan | Sonnet | 3-8K | "Plan approach for new feature" |
| **Multi-file changes** | General-Purpose | Sonnet | 10-30K | "Refactor authentication system" |
| **Deep analysis** | General-Purpose | Sonnet | 15-40K | "Analyze performance bottlenecks" |
| **Complex research** | General-Purpose | Sonnet | 20-50K | "Research best practices for X" |
| **Project management** | Project Orchestrator | Sonnet | 5-15K | "Manage this Salesforce build" |

---

## üß† Your Project Types & Skill Teams

### 1Ô∏è‚É£ Salesforce Agentforce Projects
**Triggers**: "Agentforce", "Salesforce agent", "Apex", "Flow", "Einstein"

**Skill Team**:
- `salesforce-agentforce-builder` (core)
- `dmn-ml-llm-agent-builder` (business logic)
- `conversation-synthesizer` (dialog handling)
- `reasoning-scaffold-builder` (complex decisions)
- `self-correcting-prompts` (quality validation)

**Command**:
```
"Use project orchestrator for Salesforce Agentforce: [your requirements]"
```

---

### 2Ô∏è‚É£ GoHighLevel Projects
**Triggers**: "GHL", "GoHighLevel", "workflow", "campaign", "SMS", "booking"

**Skill Team**:
- `ghl-workflow-qa-agent` (validation)
- `ghl-conversation-manager` (chatbot logic)
- `ghl-campaign-analyzer` (performance)
- `ghl-contact-enrichment-agent` (data quality)
- `ai-copywriting-agent` (messaging)

**Command**:
```
"Build GHL workflow with project orchestrator: [your requirements]"
```

---

### 3Ô∏è‚É£ Lead Generation / Outreach
**Triggers**: "cold email", "outreach", "lead scoring", "LPR", "database reactivation"

**Skill Team**:
- `vl pr-lead-scoring-engine` (scoring)
- `ai-copywriting-agent` (copy generation)
- `cold-email-orchestrator` (delivery)
- `omnichannel-orchestrator` (multi-touch)
- `sales-data-analyzer` (results tracking)

**Command**:
```
"Create lead gen campaign: [your requirements]"
```

---

### 4Ô∏è‚É£ AI Agent / Skill Development
**Triggers**: "new skill", "agent system", "prompt engineering", "Custom GPT"

**Skill Team**:
- `prompt-orchestrator` (meta-prompting)
- `reasoning-scaffold-builder` (advanced techniques)
- `self-correcting-prompts` (quality)
- `skill-debugging-assistant` (validation)
- `skill-testing-framework` (QA)

**Command**:
```
"Build new AI agent skill: [your requirements]"
```

---

### 5Ô∏è‚É£ Data Analysis / Reporting
**Triggers**: "analyze data", "create report", "dashboard", "metrics"

**Skill Team**:
- `sales-data-analyzer` (core analytics)
- `ghl-campaign-analyzer` (GHL-specific)
- `data-visualizer` (charts/graphs)
- `presentation-builder` (deliverables)

**Command**:
```
"Analyze [data source] and create [report type]"
```

---

## ‚ö° Token Optimization Techniques

### ‚úÖ DO: Token-Efficient Patterns

1. **Use Haiku-first strategy**
   ```
   "Use Haiku to quickly explore [codebase/data]"
   ```

2. **Launch parallel agents**
   ```
   "In parallel: explore codebase + research docs + analyze data"
   ```

3. **Let agents cache knowledge**
   ```
   "Use Explore agent to map architecture" (saves repeated file reads)
   ```

4. **Batch related questions**
   ```
   "Analyze X, Y, and Z in one comprehensive review"
   ```

5. **Use specialized skills**
   ```
   "Use ghl-workflow-qa-agent" (vs manual testing)
   ```

### ‚ùå DON'T: Token-Wasting Patterns

1. ~~Sequential agent launches when parallel is possible~~
2. ~~Reading same files multiple times~~
3. ~~Using Sonnet for simple searches/validations~~
4. ~~Manual testing when QA skills exist~~
5. ~~Asking me to explain code I haven't read yet~~

---

## üé¨ Example Workflows

### Example 1: Token-Optimized Exploration
**Scenario**: Understand a new codebase

**‚ùå Token-Wasting Approach** (50K+ tokens):
```
You: "Read file A"
Me: [reads file A - 3K tokens]
You: "Now read file B"
Me: [reads file B - 4K tokens]
You: "How do they connect?"
Me: [re-analyzes both - 7K tokens]
[Repeat 5x...]
```

**‚úÖ Token-Efficient Approach** (15K tokens):
```
You: "Use Explore agent (Haiku) to map the authentication system architecture"
Me: [Launches Haiku agent - explores multiple files - returns summary]
Me: [Presents synthesized architecture understanding - 3K tokens]
```

**Token Savings**: 70% reduction

---

### Example 2: Complex Project Management
**Scenario**: Build Salesforce Lost Opportunity Reactivation Agent

**‚ùå Ad-hoc Approach** (120K+ tokens, scattered execution):
```
You: "Build Salesforce agent"
Me: [reads random files]
Me: [asks clarifying questions]
You: [provides more context]
Me: [starts building]
[realizes missing requirements]
[refactors]
[manual testing]
[finds bugs]
[fixes]
```

**‚úÖ Orchestrated Approach** (60-70K tokens, systematic):
```
You: "Use project orchestrator: Build Salesforce Agentforce agent for lost opportunity reactivation"

Me: [Activates project-orchestrator-agent]
Me:
  Project Type: Salesforce Agentforce + Lead Reactivation

  Agent Team:
    - salesforce-agentforce-builder
    - conversation-synthesizer
    - dmn-ml-llm-agent-builder
    - ai-copywriting-agent

  Execution Plan: [4 phases with quality gates]
  Token Budget: 65K

  Proceed? [Y/n]

You: Y

Me: [Systematic execution with parallel agents, quality gates, validation]
Me: [Delivers complete, tested system]
```

**Token Savings**: 42% reduction + higher quality

---

## üìä Token Budget Planning

### Project Size Guidelines

| Project Size | Token Range | Approach | Example |
|-------------|-------------|----------|---------|
| **Tiny** | < 10K | Direct work, no agents | Fix typo, read 1-2 files |
| **Small** | 10-30K | Single agent, Sonnet OK | Add simple feature |
| **Medium** | 30-75K | Multiple agents, Haiku-first | Build workflow + testing |
| **Large** | 75-150K | Project orchestrator, heavy Haiku | Multi-system integration |
| **Enterprise** | 150K+ | Chunking + orchestrator | Platform development |

### When to Request Token Optimization

- You have > 3 tasks to complete
- Project spans multiple domains (Salesforce + GHL)
- You need comprehensive analysis
- Budget is a concern
- You want systematic execution

**Command**:
```
"Use token-optimized approach with project orchestrator"
```

---

## üéØ Quality Control Checklist

### Before Starting (Use Project Orchestrator)
- [ ] Project type identified
- [ ] Skill team selected
- [ ] Agent models assigned (Haiku vs Sonnet)
- [ ] Execution plan created
- [ ] Quality gates defined

### During Execution (Automatic)
- [ ] Todo list maintained
- [ ] One task in_progress at a time
- [ ] Tasks completed immediately
- [ ] Token usage monitored
- [ ] Quality checks at milestones

### Before Completion (Use QA Skills)
- [ ] Requirements met
- [ ] Tests passing
- [ ] Validation passed:
  - Salesforce: `salesforce-agentforce-builder` validation
  - GHL: `ghl-workflow-qa-agent` testing
  - AI Agents: `self-correcting-prompts` quality check
  - Skills: `skill-testing-framework` validation

---

## üîß Advanced Commands

### Force Specific Model
```
"Launch Explore agent with Haiku to quickly scan for [pattern]"
"Use Sonnet for deep analysis of [complex system]"
```

### Parallel Agent Execution
```
"In parallel:
  1. Explore authentication system
  2. Analyze database schema
  3. Review API endpoints"
```

### Skill Combination
```
"Use conversation-synthesizer + vl-pr-lead-scoring-engine + ai-copywriting-agent to build reactivation campaign"
```

### Token Budget Constraint
```
"Complete this task in under 30K tokens using Haiku-first strategy"
```

---

## üö® Common Pitfalls & Solutions

### Pitfall 1: Token Waste from Sequential Work
**Problem**: Asking questions one at a time
**Solution**: Batch questions or use project orchestrator

### Pitfall 2: Using Sonnet for Simple Tasks
**Problem**: "Read this file" ‚Üí Sonnet reads it (expensive)
**Solution**: "Use Haiku to quickly scan [files]" (10x cheaper)

### Pitfall 3: Not Leveraging Specialized Skills
**Problem**: Manual validation of GHL workflows
**Solution**: "Use ghl-workflow-qa-agent to validate"

### Pitfall 4: Scattered Execution
**Problem**: No clear plan, tasks get missed
**Solution**: "Use project orchestrator" for systematic execution

### Pitfall 5: Redundant File Reads
**Problem**: Same file read multiple times across conversation
**Solution**: Launch Explore agent early to cache understanding

---

## üéì Skill Synergy Patterns

### Pattern 1: Lost Opportunity Reactivation
```
conversation-synthesizer
  ‚Üí vl-pr-lead-scoring-engine
  ‚Üí ai-copywriting-agent
  ‚Üí omnichannel-orchestrator
  ‚Üí ghl-campaign-analyzer
```

### Pattern 2: Salesforce + GHL Integration
```
salesforce-agentforce-builder
  ‚Üí ghl-agent-orchestrator
  ‚Üí dmn-ml-llm-agent-builder (shared logic)
  ‚Üí conversation-synthesizer (dialog sync)
```

### Pattern 3: AI Agent with Learning
```
reasoning-scaffold-builder
  ‚Üí self-correcting-prompts
  ‚Üí ml-feedback-loop-architect
  ‚Üí prompt-orchestrator
```

### Pattern 4: Complete Lead Gen System
```
vl-pr-lead-scoring-engine
  ‚Üí ghl-contact-enrichment-agent
  ‚Üí ai-copywriting-agent
  ‚Üí cold-email-orchestrator
  ‚Üí sales-data-analyzer
```

---

## üìû Quick Commands Cheat Sheet

| What You Want | Command |
|---------------|---------|
| Start any complex project | "Use project orchestrator to [task]" |
| Quick codebase exploration | "Use Explore agent (Haiku) to find [pattern]" |
| Deep architectural analysis | "Use Explore agent (Sonnet - very thorough) to analyze [system]" |
| Plan before building | "Use Plan agent to design approach for [feature]" |
| Multi-step implementation | "Use project orchestrator with token optimization" |
| Validate Salesforce work | "Run salesforce-agentforce-builder validation" |
| Test GHL workflows | "Use ghl-workflow-qa-agent to test" |
| Generate AI copy | "Use ai-copywriting-agent for [campaign]" |
| Score leads | "Use vl-pr-lead-scoring-engine to evaluate [leads]" |
| Analyze data | "Use sales-data-analyzer on [data source]" |
| Create presentation | "Use presentation-builder for [topic]" |
| Debug a skill | "Use skill-debugging-assistant on [skill name]" |
| Optimize prompts | "Use reasoning-scaffold-builder for [agent logic]" |

---

## üéØ Your Current Token Budget: 200K per conversation

### Typical Project Costs
- **Small feature**: 10-30K (15% of budget)
- **Medium workflow**: 30-75K (37% of budget)
- **Large integration**: 75-150K (75% of budget)
- **Enterprise project**: 150K+ (use chunking)

### Token Monitoring
I'll show you token usage after each tool execution:
```
Token usage: 30275/200000; 169725 remaining
```

### When to Start New Conversation
- Token usage > 150K and more complex work ahead
- Context getting stale (old decisions no longer relevant)
- Project phase completed, starting new phase

---

## üí° Pro Tips

1. **Start with orchestrator for multi-domain projects**: Saves 30-50% tokens
2. **Use "in parallel" explicitly**: Forces me to launch agents simultaneously
3. **Specify model when you know**: "Use Haiku" = 10x cheaper for simple tasks
4. **Leverage your 40+ skills**: They're pre-optimized token machines
5. **Ask for token estimate**: "How many tokens will this take?"
6. **Batch related work**: One comprehensive pass > multiple small requests
7. **Trust the agents**: They see full conversation context, no need to repeat
8. **Quality gates are automatic**: When using project orchestrator

---

## üîç Debugging Commands

### Check Available Skills
```
"List all my active skills"
"Which skills apply to [project type]?"
```

### Agent Status
```
"Show current token usage"
"What agent team would you use for [task]?"
```

### Optimization Advice
```
"How can we optimize token usage for [project]?"
"What's the most efficient approach to [task]?"
```

---

## üé¨ Next Steps

1. **Try the project orchestrator**:
   ```
   "Use project orchestrator to [your next project]"
   ```

2. **Experiment with model selection**:
   ```
   "Use Haiku to explore [simple task]"
   "Use Sonnet to analyze [complex system]"
   ```

3. **Leverage skill combinations**:
   ```
   "Use [skill1] + [skill2] + [skill3] to build [system]"
   ```

4. **Monitor token efficiency**:
   ```
   "Show token usage trends for this conversation"
   ```

---

## üìö Reference Files

- **Project Orchestrator Skill**: `~/.claude/skills/project-orchestrator-agent/SKILL.md`
- **This Quick Reference**: `CircuitOS_Local_Complete_Package/AGENT_ORCHESTRATION_QUICK_REFERENCE.md`
- **Your Skills Directory**: `~/.claude/skills/` (40+ specialized skills)

---

**Remember**: The goal is **maximum efficiency** + **world-class results**. The project orchestrator ensures both by systematically managing agents, optimizing token usage, and enforcing quality control.

**Default mode for complex work**: "Use project orchestrator to [task]"

This activates the full systematic approach with token optimization, quality gates, and intelligent skill orchestration.
